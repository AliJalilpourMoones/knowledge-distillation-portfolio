# knowledge-distillation-portfolio
A knowledge distillation project to compress a BART-large summarization model into a smaller student model
